{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a8e414",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpkl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "path_source_files = '/Users/tianyichen/Desktop/Research /PhDresearch/Hopkins_Organoid'\n",
    "# Get list of all pickle files in the target directory\n",
    "filenames = os.listdir(path_source_files)\n",
    "filenames = [fn for fn in filenames if fn.endswith('.pkl')]\n",
    "sizes = []\n",
    "for f in filenames:\n",
    "    sizes.append(os.stat(os.path.join(path_source_files, f)).st_size)\n",
    "# Excluding files that are relatively small\n",
    "thresh = np.median(sizes)/4\n",
    "print(f'\\nExcluding pickle files of size less than {thresh/1e6:0.3f} MB.')\n",
    "filenames = [fn for fn, sz in zip(filenames, sizes) if sz>=thresh]\n",
    "\n",
    "# Report filenames\n",
    "path_source_files = os.path.abspath(path_source_files)\n",
    "print(f'\\nFILES IN THE SOURCE DIRECTORY: {path_source_files}')\n",
    "pprint(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=filenames[4].split('_')[2]\n",
    "datetime.date(int(dd[0]+dd[1])+2000,int(dd[2]+dd[3]),int(dd[4]+dd[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm=[0,1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_aug=np.zeros([len(tm),995,995])\n",
    "for i in range(len(tm)):\n",
    "    with open(filenames[tm[i]], 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "        well = 'well003'\n",
    "    adj_matrix = data[well]['adj_matrix_predicted']\n",
    "    l=adj_matrix.shape[0]\n",
    "    print( [filenames[tm[i]],l] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355af69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add zeros to the adj mat such that they have the same dims \n",
    "adj_aug=np.zeros([len(tm),995,995])\n",
    "for i in range(len(tm)):\n",
    "    with open(filenames[tm[i]], 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "        well = 'well003'\n",
    "    print(filenames[tm[i]])\n",
    "    adj_matrix = data[well]['adj_matrix_predicted']\n",
    "    votes = data[well]['votes']\n",
    "    corr_peaks = data[well]['corr_peaks']\n",
    "    synced_matrix = np.full(adj_matrix.shape, False)\n",
    "    for key in corr_peaks.keys():\n",
    "        if np.all(np.abs(np.array(corr_peaks[key]['delays'])) < data['parameters']['time_resolution']):\n",
    "            synced_matrix[key[0], key[1]] = True\n",
    "            synced_matrix[key[1], key[0]] = True\n",
    "    filtered_matrix = np.logical_and(data[well]['adj_matrix_predicted'], np.logical_not(synced_matrix))\n",
    "    l=filtered_matrix.shape[0]\n",
    "    adj_aug[i][:l,:l]=filtered_matrix\n",
    "    #adj_aug[i][:l,:l]=adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(adj_aug[0]>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.transpose(adj_aug[0])-adj_aug[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf41c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adj_aug[0], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd958c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(adj_aug[1]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca002bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import quadratic_assignment\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222527cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_gm=np.zeros([len(tm),995,995])\n",
    "adj_gm[0]=adj_aug[0] ## use the first graph as baseline\n",
    "for i in range(1, len(tm)):\n",
    "    res = quadratic_assignment(adj_gm[i-1],adj_aug[i],options = {'maximize': True})\n",
    "    perm = res['col_ind']\n",
    "    adj_gm[i]=adj_aug[i][perm][:,perm]\n",
    "    print([LA.norm(adj_gm[i]-adj_gm[i-1],'fro'),LA.norm(adj_aug[i]-adj_gm[i-1],'fro')]) ## make sure the difference between graphs are decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915436b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adj_gm[3], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb67117",
   "metadata": {},
   "outputs": [],
   "source": [
    "## product all adj mat to get common edges \n",
    "prod=adj_gm[0]\n",
    "for i in range(1,len(tm)):\n",
    "    prod=prod * adj_gm[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.datasets import load_drosophila_right\n",
    "from graspologic.plot import heatmap\n",
    "from graspologic.utils import binarize, symmetrize\n",
    "import graspologic.utils as graspologic_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the connected component for the common edge subgraph \n",
    "[a,ind]=graspologic_utils.largest_connected_component(prod,return_inds=True)\n",
    "len(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207dc231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check every adj mat is connected \n",
    "glist=np.zeros([len(tm),len(ind),len(ind)])\n",
    "for i in range(len(tm)):\n",
    "    glist[i]=adj_gm[i][ind][:,ind]\n",
    "    print(graspologic_utils.is_fully_connected(glist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a34cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(ind)\n",
    "## scree plot for one graph \n",
    "u,s,v=np.linalg.svd(glist[1], full_matrices=True)\n",
    "plt.scatter(range(n),s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed=1\n",
    "Xhat_list=np.zeros([len(tm),n,2*ed])\n",
    "for i in range(len(tm)):\n",
    "    ase = AdjacencySpectralEmbed(n_components=ed)\n",
    "    Xhat, Yhat = ase.fit_transform(glist[i])\n",
    "    Xhat_list[i][:,list(np.arange(ed))]=Xhat\n",
    "    Xhat_list[i][:,list(np.arange(ed,2*ed))]=Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4249ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import orthogonal_procrustes\n",
    "D=np.zeros([len(tm),len(tm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tm)):\n",
    "    for j in range(len(tm)):\n",
    "        R, sca = orthogonal_procrustes(Xhat_list[i] , Xhat_list[j] )\n",
    "        D[i,j]=LA.norm(Xhat_list[i] @ R -  Xhat_list[j],2)**2/n  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "J=np.ones([len(tm),len(tm)])/len(tm)\n",
    "I=np.eye(len(tm))\n",
    "P=I-J"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
